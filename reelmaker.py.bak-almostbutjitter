import cv2
import numpy as np
import sys
import os

def load_face_detector():
    modelFile = "res10_300x300_ssd_iter_140000_fp16.caffemodel"
    configFile = "deploy.prototxt"
    net = cv2.dnn.readNetFromCaffe(configFile, modelFile)
    return net

def detect_faces_dnn(net, frame):
    blob = cv2.dnn.blobFromImage(
        cv2.resize(frame, (300, 300)),
        1.0,
        (300, 300),
        [104.0, 177.0, 123.0],
        False,
        False,
    )
    net.setInput(blob)
    detections = net.forward()

    h, w = frame.shape[:2]
    faces = []
    for i in range(detections.shape[2]):
        confidence = detections[0, 0, i, 2]
        if confidence > 0.6:  # Adjust confidence threshold if necessary
            x1 = int(detections[0, 0, i, 3] * w)
            y1 = int(detections[0, 0, i, 4] * h)
            x2 = int(detections[0, 0, i, 5] * w)
            y2 = int(detections[0, 0, i, 6] * h)
            faces.append([x1, y1, x2, y2])
    return faces

def compute_motion_between_frames(prev_gray, curr_gray):
    # Compute absolute difference between frames
    diff = cv2.absdiff(prev_gray, curr_gray)
    # Threshold to binarize the difference
    _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)
    return thresh

def analyze_video(input_video):
    net = load_face_detector()
    cap = cv2.VideoCapture(input_video)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)

    face_positions = []
    motion_positions = []

    ret, prev_frame = cap.read()
    if not ret:
        print(f"Error reading video {input_video} for analysis.")
        cap.release()
        return None, None

    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)

    frame_idx = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        curr_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Detect faces
        faces = detect_faces_dnn(net, frame)
        if faces:
            # Use the largest face
            largest_face = max(faces, key=lambda rect: (rect[2]-rect[0]) * (rect[3]-rect[1]))
            face_positions.append(largest_face)
        else:
            face_positions.append(None)

        # Compute motion
        motion_mask = compute_motion_between_frames(prev_gray, curr_gray)
        # Find contours of the motion areas
        contours, _ = cv2.findContours(motion_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours:
            # Get the largest contour
            largest_contour = max(contours, key=cv2.contourArea)
            # Get bounding rectangle
            x, y, w, h = cv2.boundingRect(largest_contour)
            motion_positions.append([x, y, w, h])
        else:
            motion_positions.append(None)

        prev_gray = curr_gray
        frame_idx += 1

    cap.release()

    return face_positions, motion_positions

def smooth_positions(positions, max_movement_per_frame):
    """
    Smooth the positions to prevent erratic movements.

    positions: List of (x, y) tuples or None.
    max_movement_per_frame: Maximum allowed movement per frame.
    """
    smoothed_positions = []
    prev_pos = None
    for pos in positions:
        if pos is not None:
            if prev_pos is not None:
                # Limit the movement
                dx = pos[0] - prev_pos[0]
                dy = pos[1] - prev_pos[1]
                dist = np.sqrt(dx*dx + dy*dy)
                if dist > max_movement_per_frame:
                    scale = max_movement_per_frame / dist
                    dx *= scale
                    dy *= scale
                    pos = (prev_pos[0] + dx, prev_pos[1] + dy)
            smoothed_positions.append(pos)
            prev_pos = pos
        else:
            # If current position is None, keep previous position
            smoothed_positions.append(prev_pos)
    return smoothed_positions

def compute_crop_positions(face_positions, motion_positions, frame_dims, output_aspect_ratio=9/16.0):
    """
    Compute the crop positions for each frame.

    face_positions: List of face bounding boxes or None.
    motion_positions: List of motion bounding boxes or None.
    frame_dims: (height, width) of the frames.
    output_aspect_ratio: Desired output aspect ratio.
    """
    h_frame, w_frame = frame_dims

    # Compute centers for each frame
    centers = []
    for face_bbox, motion_bbox in zip(face_positions, motion_positions):
        if face_bbox is not None:
            x1, y1, x2, y2 = face_bbox
            face_center_x = x1 + (x2 - x1) // 2
            face_center_y = y1 + (y2 - y1) // 2
            centers.append((face_center_x, face_center_y))
        elif motion_bbox is not None:
            x_motion, y_motion, w_motion, h_motion = motion_bbox
            motion_center_x = x_motion + w_motion // 2
            motion_center_y = y_motion + h_motion // 2
            centers.append((motion_center_x, motion_center_y))
        else:
            centers.append(None)

    # Smooth centers to prevent erratic movement
    max_movement_per_frame = 20  # Adjust as needed (20% variance)
    smoothed_centers = smooth_positions(centers, max_movement_per_frame)

    # Compute crop rectangles for each frame
    crop_rects = []
    output_width = int(h_frame * output_aspect_ratio)
    output_height = h_frame

    if output_width > w_frame:
        output_width = w_frame
        output_height = int(w_frame / output_aspect_ratio)

    for center in smoothed_centers:
        if center is not None:
            center_x, center_y = center
            x1_crop = int(center_x - output_width // 2)
            y1_crop = int(center_y - output_height // 2)
        else:
            # Default to center of frame
            x1_crop = int((w_frame - output_width) // 2)
            y1_crop = int((h_frame - output_height) // 2)

        # Ensure cropping rectangle stays within frame bounds
        x1_crop = max(0, min(x1_crop, w_frame - output_width))
        y1_crop = max(0, min(y1_crop, h_frame - output_height))

        crop_rects.append((x1_crop, y1_crop, output_width, output_height))

    return crop_rects

def process_video_with_crops(input_video, output_video, crop_rects, desired_size=(1080, 1920)):
    cap = cv2.VideoCapture(input_video)
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = len(crop_rects)

    # Prepare video writer
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video, fourcc, fps, desired_size)

    frame_idx = 0
    ret, frame = cap.read()
    while ret and frame_idx < total_frames:
        x1_crop, y1_crop, output_width, output_height = crop_rects[frame_idx]
        cropped_frame = frame[y1_crop : y1_crop + output_height, x1_crop : x1_crop + output_width]
        resized_frame = cv2.resize(cropped_frame, desired_size, interpolation=cv2.INTER_AREA)
        out.write(resized_frame)

        ret, frame = cap.read()
        frame_idx += 1

    cap.release()
    out.release()

def main():
    if len(sys.argv) != 2:
        print("Usage: python reelmaker.py input_directory")
        sys.exit(1)

    input_dir = sys.argv[1]
    if not os.path.isdir(input_dir):
        print(f"The provided input '{input_dir}' is not a directory.")
        sys.exit(1)

    # Get list of all mp4 files in the directory
    video_files = [f for f in os.listdir(input_dir) if f.lower().endswith('.mp4')]

    if not video_files:
        print(f"No .mp4 files found in directory '{input_dir}'.")
        sys.exit(1)

    output_dir = os.path.join(input_dir, 'processed_videos')
    os.makedirs(output_dir, exist_ok=True)

    for video_file in video_files:
        input_video = os.path.join(input_dir, video_file)
        output_video = os.path.join(output_dir, f"processed_{video_file}")
        print(f"Processing {input_video}...")
        try:
            # Analyze video
            face_positions, motion_positions = analyze_video(input_video)
            if face_positions is None or motion_positions is None:
                print(f"Skipping {input_video} due to analysis failure.")
                continue

            # Get frame dimensions
            cap = cv2.VideoCapture(input_video)
            h_frame = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            w_frame = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            cap.release()
            frame_dims = (h_frame, w_frame)

            # Compute crop positions
            crop_rects = compute_crop_positions(face_positions, motion_positions, frame_dims)

            # Process video with computed crops
            process_video_with_crops(input_video, output_video, crop_rects)

        except Exception as e:
            print(f"An error occurred while processing {input_video}: {e}")

    print("Processing complete.")

if __name__ == "__main__":
    main()
