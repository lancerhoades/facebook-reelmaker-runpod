import cv2
import numpy as np
import moviepy.editor as mpy
import sys
import os

def load_face_detector():
    modelFile = "res10_300x300_ssd_iter_140000_fp16.caffemodel"
    configFile = "deploy.prototxt"
    net = cv2.dnn.readNetFromCaffe(configFile, modelFile)
    return net

def detect_faces_dnn(net, frame):
    blob = cv2.dnn.blobFromImage(
        cv2.resize(frame, (300, 300)),
        1.0,
        (300, 300),
        [104.0, 177.0, 123.0],
        False,
        False,
    )
    net.setInput(blob)
    detections = net.forward()

    h, w = frame.shape[:2]
    faces = []
    for i in range(detections.shape[2]):
        confidence = detections[0, 0, i, 2]
        if confidence > 0.6:  # Adjust confidence threshold if necessary
            x1 = int(detections[0, 0, i, 3] * w)
            y1 = int(detections[0, 0, i, 4] * h)
            x2 = int(detections[0, 0, i, 5] * w)
            y2 = int(detections[0, 0, i, 6] * h)
            faces.append([x1, y1, x2, y2])
    return faces

def compute_motion_between_frames(prev_gray, curr_gray):
    # Compute absolute difference between frames
    diff = cv2.absdiff(prev_gray, curr_gray)
    # Threshold to binarize the difference
    _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)
    return thresh

def analyze_video(input_video):
    net = load_face_detector()
    clip = mpy.VideoFileClip(input_video)
    frame_count = int(clip.fps * clip.duration)
    fps = clip.fps

    face_positions = []
    motion_positions = []

    frames = []
    for frame in clip.iter_frames():
        frames.append(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))

    prev_gray = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)

    for idx, frame in enumerate(frames):
        curr_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Detect faces
        faces = detect_faces_dnn(net, frame)
        if faces:
            # Use the largest face
            largest_face = max(faces, key=lambda rect: (rect[2]-rect[0]) * (rect[3]-rect[1]))
            face_positions.append(largest_face)
        else:
            face_positions.append(None)

        # Compute motion
        motion_mask = compute_motion_between_frames(prev_gray, curr_gray)
        # Find contours of the motion areas
        contours, _ = cv2.findContours(motion_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours:
            # Get the largest contour
            largest_contour = max(contours, key=cv2.contourArea)
            # Get bounding rectangle
            x, y, w, h = cv2.boundingRect(largest_contour)
            motion_positions.append([x, y, w, h])
        else:
            motion_positions.append(None)

        prev_gray = curr_gray

    frame_dims = frames[0].shape[:2]  # (height, width)
    return face_positions, motion_positions, fps, frame_dims, frames

def compute_crop_positions(face_positions, motion_positions, frame_dims, fps, output_aspect_ratio=9/16.0):
    """
    Compute the crop positions for each frame.
    We update the target position every second and interpolate between them.
    """
    h_frame, w_frame = frame_dims

    # Compute centers for each frame
    centers = []
    for face_bbox, motion_bbox in zip(face_positions, motion_positions):
        if face_bbox is not None:
            x1, y1, x2, y2 = face_bbox
            face_center_x = x1 + (x2 - x1) // 2
            face_center_y = y1 + (y2 - y1) // 2
            centers.append((face_center_x, face_center_y))
        elif motion_bbox is not None:
            x_motion, y_motion, w_motion, h_motion = motion_bbox
            motion_center_x = x_motion + w_motion // 2
            motion_center_y = y_motion + h_motion // 2
            centers.append((motion_center_x, motion_center_y))
        else:
            centers.append(None)

    # Handle missing centers by forward-filling
    for i in range(len(centers)):
        if centers[i] is None:
            if i > 0:
                centers[i] = centers[i - 1]
            else:
                # Default to center of frame if first frame
                centers[i] = (w_frame // 2, h_frame // 2)

    # Segment into 1-second intervals
    frames_per_segment = int(fps)
    num_segments = int(np.ceil(len(centers) / frames_per_segment))
    segment_centers = []

    for i in range(num_segments):
        start_idx = i * frames_per_segment
        end_idx = min((i + 1) * frames_per_segment, len(centers))
        segment = centers[start_idx:end_idx]
        # Compute average center for the segment
        avg_x = int(np.mean([c[0] for c in segment]))
        avg_y = int(np.mean([c[1] for c in segment]))
        segment_centers.append((avg_x, avg_y))

    # Interpolate between segment centers over the frames
    crop_rects = []
    output_width = int(h_frame * output_aspect_ratio)
    output_height = h_frame

    if output_width > w_frame:
        output_width = w_frame
        output_height = int(w_frame / output_aspect_ratio)

    total_frames = len(centers)
    for i in range(total_frames):
        # Determine which segments we are interpolating between
        segment_idx = i // frames_per_segment
        t = (i % frames_per_segment) / frames_per_segment  # Normalized time within the segment

        # Get current and next segment centers
        current_center = segment_centers[segment_idx]
        if segment_idx + 1 < len(segment_centers):
            next_center = segment_centers[segment_idx + 1]
        else:
            next_center = current_center  # Stay at the last center

        # Linear interpolation between current and next center
        center_x = int((1 - t) * current_center[0] + t * next_center[0])
        center_y = int((1 - t) * current_center[1] + t * next_center[1])

        # Compute crop rectangle
        x1_crop = int(center_x - output_width // 2)
        y1_crop = int(center_y - output_height // 2)

        # Ensure cropping rectangle stays within frame bounds
        x1_crop = max(0, min(x1_crop, w_frame - output_width))
        y1_crop = max(0, min(y1_crop, h_frame - output_height))

        crop_rects.append((x1_crop, y1_crop, output_width, output_height))

    return crop_rects

def process_video_with_crops(frames, crop_rects, desired_size=(1080, 1920)):
    processed_frames = []
    total_frames = len(crop_rects)

    for frame_idx in range(total_frames):
        frame = frames[frame_idx]
        x1_crop, y1_crop, output_width, output_height = crop_rects[frame_idx]
        cropped_frame = frame[y1_crop : y1_crop + output_height, x1_crop : x1_crop + output_width]
        resized_frame = cv2.resize(cropped_frame, desired_size, interpolation=cv2.INTER_AREA)
        # Convert back to RGB for MoviePy
        resized_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)
        processed_frames.append(resized_frame)

    return processed_frames

def main():
    if len(sys.argv) != 2:
        print("Usage: python reelmaker.py input_directory")
        sys.exit(1)

    input_dir = sys.argv[1]
    if not os.path.isdir(input_dir):
        print(f"The provided input '{input_dir}' is not a directory.")
        sys.exit(1)

    # Get list of all mp4 files in the directory
    video_files = [f for f in os.listdir(input_dir) if f.lower().endswith('.mp4')]

    if not video_files:
        print(f"No .mp4 files found in directory '{input_dir}'.")
        sys.exit(1)

    output_dir = os.path.join(input_dir, 'processed_videos')
    os.makedirs(output_dir, exist_ok=True)

    for video_file in video_files:
        input_video = os.path.join(input_dir, video_file)
        output_video = os.path.join(output_dir, f"processed_{video_file}")
        print(f"Processing {input_video}...")
        try:
            # Analyze video
            face_positions, motion_positions, fps, frame_dims, frames = analyze_video(input_video)
            if face_positions is None or motion_positions is None:
                print(f"Skipping {input_video} due to analysis failure.")
                continue

            # Compute crop positions
            crop_rects = compute_crop_positions(face_positions, motion_positions, frame_dims, fps)

            # Process video with computed crops
            processed_frames = process_video_with_crops(frames, crop_rects)

            # Create a new video clip with the processed frames and original audio
            clip = mpy.VideoFileClip(input_video)
            processed_clip = mpy.ImageSequenceClip(processed_frames, fps=fps)
            processed_clip = processed_clip.set_audio(clip.audio)
            processed_clip.write_videofile(output_video, codec="libx264", audio_codec="aac")

        except Exception as e:
            print(f"An error occurred while processing {input_video}: {e}")

    print("Processing complete.")

if __name__ == "__main__":
    main()
